{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example \n",
    "\n",
    "# Create detector\n",
    "from eqcorrscan.core import subspace\n",
    "detector = subspace.Detector()\n",
    "\n",
    "from obspy import read\n",
    "import glob\n",
    "import os\n",
    "from eqcorrscan import tests\n",
    "# Get the path for the test-data so we can test this\n",
    "TEST_PATH = os.path.dirname(tests.__file__)\n",
    "wavefiles = glob.glob(\n",
    "   TEST_PATH + '/test_data/similar_events_processed/*')\n",
    "wavefiles.sort()  # Sort the wavefiles to ensure reproducibility\n",
    "streams = [read(w) for w in wavefiles[0:3]]\n",
    "# Channels must all be the same length\n",
    "detector.construct(streams=streams, lowcut=2, highcut=9, filt_order=4,\n",
    "                   sampling_rate=20, multiplex=True, name='Test_1',\n",
    "                   align=True, shift_len=0.5, reject=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions of subspace detector\n",
    "detector.partition(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate detector.data \n",
    "percent_capture = detector.energy_capture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use detector to detect within continuous data\n",
    "stream = read(wavefiles[0])\n",
    "detections = detector.detect(st=stream, threshold=0.5, trig_int=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced example\n",
    "\n",
    "\"\"\"\n",
    "Advanced subspace tutorial to show some of the capabilities of the method.\n",
    "\n",
    "This example uses waveforms from a known earthquake sequence (in the Wairarapa\n",
    "region north of Wellington, New Zealand). The catalogue locations etc can\n",
    "be downloaded from this link:\n",
    "\n",
    "http://quakesearch.geonet.org.nz/services/1.0.0/csv?bbox=175.37956,-40.97912,175.53097,-40.84628&startdate=2015-7-18T2:00:00&enddate=2016-7-18T3:00:00\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "\n",
    "from http.client import IncompleteRead\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime, Stream\n",
    "\n",
    "from eqcorrscan.utils.catalog_utils import filter_picks\n",
    "from eqcorrscan.utils.clustering import catalog_cluster\n",
    "from eqcorrscan.core import subspace\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s\\t%(name)s\\t%(levelname)s\\t%(message)s\")\n",
    "\n",
    "\n",
    "def run_tutorial(plot=False, multiplex=True, return_streams=False, cores=4,\n",
    "                 verbose=False):\n",
    "    \"\"\"\n",
    "    Run the tutorial.\n",
    "\n",
    "    :return: detections\n",
    "    \"\"\"\n",
    "    client = Client(\"GEONET\", debug=verbose)\n",
    "    cat = client.get_events(\n",
    "        minlatitude=-40.98, maxlatitude=-40.85, minlongitude=175.4,\n",
    "        maxlongitude=175.5, starttime=UTCDateTime(2016, 5, 1),\n",
    "        endtime=UTCDateTime(2016, 5, 20))\n",
    "    print(f\"Downloaded a catalog of {len(cat)} events\")\n",
    "    # This gives us a catalog of events - it takes a while to download all\n",
    "    # the information, so give it a bit!\n",
    "    # We will generate a five station, multi-channel detector.\n",
    "    cat = filter_picks(catalog=cat, top_n_picks=5)\n",
    "    stachans = list(set(\n",
    "        [(pick.waveform_id.station_code, pick.waveform_id.channel_code)\n",
    "         for event in cat for pick in event.picks]))\n",
    "    # In this tutorial we will only work on one cluster, defined spatially.\n",
    "    # You can work on multiple clusters, or try to whole set.\n",
    "    clusters = catalog_cluster(\n",
    "        catalog=cat, metric=\"distance\", thresh=2, show=False)\n",
    "    # We will work on the largest cluster\n",
    "    cluster = sorted(clusters, key=lambda c: len(c))[-1]\n",
    "    # This cluster contains 32 events, we will now download and trim the\n",
    "    # waveforms.  Note that each chanel must start at the same time and be the\n",
    "    # same length for multiplexing.  If not multiplexing EQcorrscan will\n",
    "    # maintain the individual differences in time between channels and delay\n",
    "    # the detection statistics by that amount before stacking and detection.\n",
    "    client = Client('GEONET')\n",
    "    design_set = []\n",
    "    st = Stream()\n",
    "    for event in cluster:\n",
    "        print(f\"Downloading for event {event.resource_id.id}\")\n",
    "        bulk_info = []\n",
    "        t1 = event.origins[0].time\n",
    "        t2 = t1 + 25.1  # Have to download extra data, otherwise GeoNet will\n",
    "        # trim wherever suits.\n",
    "        t1 -= 0.1\n",
    "        for station, channel in stachans:\n",
    "            try:\n",
    "                st += client.get_waveforms(\n",
    "                    'NZ', station, '*', channel[0:2] + '?', t1, t2)\n",
    "            except IncompleteRead:\n",
    "                print(f\"Could not download for {station} {channel}\")\n",
    "    print(f\"Downloaded {len(st)} channels\")\n",
    "    for event in cluster:\n",
    "        t1 = event.origins[0].time\n",
    "        t2 = t1 + 25\n",
    "        design_set.append(st.copy().trim(t1, t2))\n",
    "    # Construction of the detector will process the traces, then align them,\n",
    "    # before multiplexing.\n",
    "    print(\"Making detector\")\n",
    "    detector = subspace.Detector()\n",
    "    detector.construct(\n",
    "        streams=design_set, lowcut=2.0, highcut=9.0, filt_order=4,\n",
    "        sampling_rate=20, multiplex=multiplex, name='Wairarapa1', align=True,\n",
    "        reject=0.2, shift_len=6, plot=plot).partition(9)\n",
    "    print(\"Constructed Detector\")\n",
    "    if plot:\n",
    "        detector.plot()\n",
    "    # We also want the continuous stream to detect in.\n",
    "    t1 = UTCDateTime(2016, 5, 11, 19)\n",
    "    t2 = UTCDateTime(2016, 5, 11, 20)\n",
    "    # We are going to look in a single hour just to minimize cost, but you can\n",
    "    # run for much longer.\n",
    "    bulk_info = [('NZ', stachan[0], '*',\n",
    "                  stachan[1][0] + '?' + stachan[1][-1],\n",
    "                  t1, t2) for stachan in detector.stachans]\n",
    "    print(\"Downloading continuous data\")\n",
    "    st = client.get_waveforms_bulk(bulk_info)\n",
    "    st.merge().detrend('simple').trim(starttime=t1, endtime=t2)\n",
    "    # We set a very low threshold because the detector is not that great, we\n",
    "    # haven't aligned it particularly well - however, at this threshold we make\n",
    "    # two real detections.\n",
    "    print(\"Computing detections\")\n",
    "    detections, det_streams = detector.detect(\n",
    "        st=st, threshold=0.4, trig_int=2, extract_detections=True,\n",
    "        cores=cores)\n",
    "    if return_streams:\n",
    "        return detections, det_streams\n",
    "    else:\n",
    "        return detections\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_tutorial()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eqcorrscan",
   "language": "python",
   "name": "eqcorrscan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
